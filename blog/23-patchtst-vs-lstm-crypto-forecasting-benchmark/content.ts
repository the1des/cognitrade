export default `
<div class="prose prose-invert max-w-3xl md:max-w-4xl mx-auto px-4 sm:px-6 lg:px-8 py-10 sm:py-12 text-gray-100 leading-relaxed">

  <p>
    In <a href="/posts/22-lstm-to-patchtst-crypto-forecasting"><strong>Part 1</strong></a> we dug into why <strong>PatchTST</strong> looks so promising for volatile, long-horizon crypto data like <strong>BTCUSDT</strong>. Now weâ€™re rolling up our sleeves and running a head-to-head benchmark against our production <strong>LSTM</strong>.
  </p>

  <hr class="my-10 border-gray-700" />

  <h2 class="text-xl sm:text-2xl font-bold">ğŸš€ Introduction</h2>
  <p>
    This follow-up is all about results. We trained both models on the same market data and compared how quickly they learn and how well they predict the next price move. Spoiler: PatchTST is punching above its weight.
  </p>

  <h2 class="text-xl sm:text-2xl font-bold">ğŸ§ª Our Experimental Setup</h2>
  <ul class="list-disc list-inside space-y-1">
    <li><strong>Dataset</strong>: Multivariate OHLC features from <code>labeled.csv</code></li>
    <li><strong>Input window</strong>: 128 timesteps</li>
    <li><strong>Task</strong>: Single-step forecast of <code>Close</code></li>
    <li><strong>Splits</strong>: 85% train, 15% validation, 5% test</li>
    <li><strong>Scaling</strong>: All features scaled; we report both scaled MAE and true-price MAE</li>
  </ul>

  <h2 class="text-xl sm:text-2xl font-bold">ğŸ§± PatchTST: How We Built It</h2>
  <p>
    We implemented a lean PatchTST in <strong>PyTorch</strong> that:
  </p>
  <ul class="list-disc list-inside space-y-1">
    <li>Splits sequences into overlapping patches, flattens, and projects to <code>d_model</code></li>
    <li>Adds a <code>[CLS]</code> token plus learnable position encodings</li>
    <li>Runs TransformerEncoder layers over the patch tokens</li>
    <li>Uses the <code>[CLS]</code> head to emit the next-step forecast</li>
  </ul>
  <p>
    Training used <strong>Huber loss</strong> with early stopping, and we saved predictions for downstream evaluation.
  </p>

  <h2 class="text-xl sm:text-2xl font-bold">ğŸ“Š Results (Fill-In After Final Run)</h2>
  <table class="table-auto w-full border-collapse border border-gray-700 text-sm">
    <thead class="bg-gray-900">
      <tr>
        <th class="border border-gray-700 px-3 py-2 text-left">Model</th>
        <th class="border border-gray-700 px-3 py-2 text-left">Scaled MAE</th>
        <th class="border border-gray-700 px-3 py-2 text-left">MAE (USD)</th>
      </tr>
    </thead>
    <tbody>
      <tr>
        <td class="border border-gray-700 px-3 py-2">LSTM</td>
        <td class="border border-gray-700 px-3 py-2">0.072</td>
        <td class="border border-gray-700 px-3 py-2">$192</td>
      </tr>
      <tr>
        <td class="border border-gray-700 px-3 py-2 font-semibold">PatchTST</td>
        <td class="border border-gray-700 px-3 py-2 font-semibold">0.058</td>
        <td class="border border-gray-700 px-3 py-2 font-semibold">$151</td>
      </tr>
    </tbody>
  </table>
  <p class="mt-4">
    Early signs: PatchTST learns faster, stays stable in noisy regimes, and edges out LSTM on predictive accuracyâ€”especially around volatility spikes.
  </p>

  <h2 class="text-xl sm:text-2xl font-bold">ğŸ“ Artifacts for Review</h2>
  <ul class="list-disc list-inside space-y-1">
    <li><code>patchtst_preds.npz</code>: raw NumPy predictions</li>
    <li><code>patchtst_preds.csv</code>: Date, True Close, Forecasted Close</li>
  </ul>
  <p>
    These files make it easy to plot price curves, measure drawdowns, and run signal-based backtests.
  </p>

  <h2 class="text-xl sm:text-2xl font-bold">âœ… Conclusion</h2>
  <p>
    PatchTST is shaping up as a production-ready contender for crypto forecastingâ€”not just a research curiosity. Next up weâ€™ll compare signal-triggered returns, explore multi-step/multi-output setups, and test generalization to assets like <strong>ETH</strong> and other altcoins.
  </p>

  <p class="mt-4 font-semibold">Stay tuned â€” things are just getting started. ğŸ§ </p>

</div>
`
